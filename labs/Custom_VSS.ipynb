{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13a84f0-840c-4a24-a936-e26a22285804",
   "metadata": {},
   "source": [
    "# Customizing VSS Blueprint\n",
    "\n",
    "In this excercise, we will create an agent to assist with bridge inspections. This agent will identify issues from drone footage detailing the condition of the bridge. Cosmetic issues should be differentiated from structual issues. Vandalism and landscaping issues should also be reported.\n",
    "\n",
    "**Remember:** For a quick reminder, go back and check [Intro_To_VSS.ipynb](Intro_To_VSS.ipynb).\n",
    "\n",
    "\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "But first, the standard imports, settings, and helpers from last excercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d409cba2-2148-4775-8259-e593794c6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports\n",
    "from IPython.display import Markdown, Video\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from typing import Literal, Any\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import wizards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334fcb7a-5151-4b90-8e31-a4f73e7a2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths and locations\n",
    "VSS_URL = \"http://via-server:8100\"\n",
    "BRIDGE_VIDEO = Path(\"./bridge.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb34676f-eb80-407d-b979-eb6c5d0a9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for talking to the API\n",
    "def check_response(response):\n",
    "    \"\"\"Return the proper response.\"\"\"\n",
    "    print(f\"Response Code: {response.status_code}\")\n",
    "    response.raise_for_status()\n",
    "    try:\n",
    "        return response.json()\n",
    "    except requests.exceptions.JSONDecodeError:\n",
    "        return response.text\n",
    "\n",
    "def vss_api_call(\n",
    "        target: str,\n",
    "        params: None | dict[str, str] = None,\n",
    "        verb: Literal[\"get\"] | Literal [\"post\"] = \"get\",\n",
    "        json: Any = None,\n",
    "        files: Any = None,\n",
    "        data: Any = None,\n",
    "    ) -> dict[str, Any] | str:\n",
    "    \"\"\"Query the VIA Agent API and handle the response.\"\"\"\n",
    "    # determine the full url\n",
    "    url = urljoin(VSS_URL, target)\n",
    "\n",
    "    # query the api\n",
    "    if verb == \"get\":\n",
    "        response = requests.get(url, params=params)\n",
    "    elif verb == \"post\":\n",
    "        response = requests.post(url, params=params, json=json, data=data, files=files)\n",
    "    else:\n",
    "        raise ValueError(\"Verb must be either get or post.\")\n",
    "\n",
    "    return check_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b51d447-a2bc-4ad4-82e4-dae751095796",
   "metadata": {},
   "source": [
    "## Inspect drone footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff92a94a-cc4c-4aa6-8888-32106b70c396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"bridge.mp4\" controls  width=\"350\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(BRIDGE_VIDEO, width=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c48b02a-69e0-48ba-9408-0818a61bfe8b",
   "metadata": {},
   "source": [
    "## Query the available models\n",
    "\n",
    "Create a variable called `models_response` that is the list of the available models. \n",
    "\n",
    "<details>\n",
    "    <summary><b>ðŸ’¢ Stuck?</b></summary>\n",
    "\n",
    "```python\n",
    "models_response = vss_api_call(\"models\")\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465c4111-1ab6-485c-aeb0-71975a75888d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Code: 200\n"
     ]
    }
   ],
   "source": [
    "# askme\n",
    "models_response = vss_api_call(\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffc4ac6-671b-43d6-8d38-02f8efe705a8",
   "metadata": {},
   "source": [
    "## Upload the video file\n",
    "\n",
    "In order for the blueprint to access the video file, we must first upload it. This is a simple post to the files API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb374d78-ac58-49d2-9d22-e00045f31795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Code: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '899f58fe-739f-43c0-b2b9-1d191f073bb7',\n",
       " 'bytes': 112950948,\n",
       " 'filename': 'bridge.mp4',\n",
       " 'purpose': 'vision',\n",
       " 'media_type': 'video'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with BRIDGE_VIDEO.open(\"rb\") as file:\n",
    "    # setup query data\n",
    "    files = {\"file\": (BRIDGE_VIDEO.name, file)}\n",
    "    data = {\"purpose\":\"vision\", \"media_type\":\"video\"}\n",
    "\n",
    "    # query the vss api\n",
    "    upload_response = vss_api_call(\n",
    "        \"files\",\n",
    "        verb=\"post\",\n",
    "        files=files,\n",
    "        data=data\n",
    "    )\n",
    "\n",
    "upload_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8250ac4-4659-4ba8-9e23-900a36a8f74f",
   "metadata": {},
   "source": [
    "## Customize Prompts\n",
    "\n",
    "We will also need tailored prompts. \n",
    "First, write a `prompt` that instructs the VLM what to look for.\n",
    "\n",
    "Remember, these usually have three parts:\n",
    "1. Persona\n",
    "2. Details\n",
    "3. Format\n",
    "\n",
    "<details>\n",
    "    <summary><b>ðŸ’¢ Stuck?</b></summary>\n",
    "\n",
    "```python\n",
    "prompt = (\n",
    "    \"You are a bridge inspector. \"\n",
    "    \"Describe any concerns you have with this bridge in detail. \"\n",
    "    \"Your concerns may be: \"\n",
    "    \"cosmetic, structural, landscaping, or vandalism in nature.\"\n",
    "    \"Start each event description with a start and end time stamp of the event.\"\n",
    ")\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1163c9fc-27f7-48a5-9a32-3a0d4593d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# askme\n",
    "prompt = (\n",
    "    \"You are a bridge inspector. \"\n",
    "    \"Describe any concerns you have with this bridge in detail. \"\n",
    "    \"Your concerns may be: \"\n",
    "    \"cosmetic, structural, landscaping, or vandalism in nature.\"\n",
    "    \"Start each event description with a start and end time stamp of the event.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf17e94-6bd9-4f7d-a893-7c5d1703e763",
   "metadata": {},
   "source": [
    "Next we write the `caption_summarization_prompt`. This is the one that rarely changes, so we can start with the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f299e8b1-25c2-4867-9fbd-31686c674923",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_summarization_prompt = (\n",
    "    \"If any descriptions have the same meaning and are sequential \"\n",
    "    \"then combine them under one sentence and merge the time stamps \"\n",
    "    \"to a range. Format the timestamps as 'mm:ss'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6830d34-0dc3-4776-bc1e-784a8c0366ca",
   "metadata": {},
   "source": [
    "Finally, the `summary_aggregation_prompt` that is used to generate the final summary. Best practice is for this to reiterate what details need to be included in the summary and any formatting options.\n",
    "\n",
    "<details>\n",
    "    <summary><b>ðŸ’¢ Stuck?</b></summary>\n",
    "\n",
    "```python\n",
    "summary_aggregation_prompt = (\n",
    "    \"Based on the available information, generate a report \"\n",
    "    \"that describes the condition of the bridge. The report \"\n",
    "    \"should be organized into cosemetic, structual, vegetation \"\n",
    "    \"overgrowth, and vandalism. The report must include timestamps. \"\n",
    "    \"This should be a concise, yet descriptive summary of all \"\n",
    "    \"the important events. The format should be intuitive and \"\n",
    "    \"easy for a user to understand what happened. Format the \"\n",
    "    \"output in Markdown so it can be displayed nicely.\"\n",
    ")\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99bc89fe-2b76-47df-a63c-7bf83e3d334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# askme\n",
    "summary_aggregation_prompt = (\n",
    "    \"Based on the available information, generate a report \"\n",
    "    \"that describes the condition of the bridge. The report \"\n",
    "    \"should be organized into cosemetic, structual, vegetation \"\n",
    "    \"overgrowth, and vandalism. The report must include timestamps. \"\n",
    "    \"This should be a concise, yet descriptive summary of all \"\n",
    "    \"the important events. The format should be intuitive and \"\n",
    "    \"easy for a user to understand what happened. Format the \"\n",
    "    \"output in Markdown so it can be displayed nicely.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab3070-7782-45a8-a1a3-9dcf79bcbf22",
   "metadata": {},
   "source": [
    "Everything is now in place to start some basic testing. Starting with basic parameters will be good enough to test the prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "703d79b9-e64e-4bf0-b80a-55d075fc285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"id\": upload_response.get(\"id\"),\n",
    "    \"prompt\": prompt,\n",
    "    \"caption_summarization_prompt\": caption_summarization_prompt,\n",
    "    \"summary_aggregation_prompt\": summary_aggregation_prompt,\n",
    "    \"model\": models_response[\"data\"][0][\"id\"],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.4,\n",
    "    \"top_p\": 1,\n",
    "    \"seed\": 1,\n",
    "    \"num_frames_per_chunk\": 10,\n",
    "    \"chunk_duration\": 30,\n",
    "    \"chunk_overlap_duration\": 0,\n",
    "    \"enable_chat\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40259415-23a1-4074-9734-8eee06b7b8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Code: 200\n",
      "**Bridge Condition Report**\n",
      "==========================\n",
      "\n",
      "### Cosmetic\n",
      "\n",
      "* 30.0-57.0: The bridge has a lot of rust on it.\n",
      "* 60.0-87.0: Rusting, graffiti, and stains on the concrete are present.\n",
      "* 120.0-147.0: Rust on the steel beam, graffiti, and stains on the concrete are present.\n",
      "* 150.0-177.0: Rust on the metal beam, dirt and debris on the concrete surface, and graffiti on the right side are present.\n",
      "\n",
      "### Structural\n",
      "\n",
      "* 60.0-87.0: No visible signs of structural damage or significant wear.\n",
      "* 120.0-147.0: No visible signs of structural damage or significant wear.\n",
      "* 150.0-177.0: No visible signs of structural damage or significant wear.\n",
      "\n",
      "### Vegetation Overgrowth\n",
      "\n",
      "* 60.0-87.0: Vegetation growth is present.\n",
      "* 120.0-147.0: Vegetation growth is present.\n",
      "* 150.0-177.0: Vegetation growth on the left side is present.\n",
      "\n",
      "### Vandalism\n",
      "\n",
      "* 60.0-87.0: Graffiti is present.\n",
      "* 120.0-147.0: Graffiti is present.\n",
      "* 150.0-177.0: Graffiti on the right side is present.\n",
      "\n",
      "### Disrepair\n",
      "\n",
      "* 90.0-117.0: The bridge is in a state of disrepair, with crumbling concrete, graffiti, and overgrown vegetation.\n",
      "\n",
      "Note: The timestamps are in the format `<start_time>-<end_time>`.\n"
     ]
    }
   ],
   "source": [
    "summarize_response = vss_api_call(\"summarize\", verb=\"post\", json=body)\n",
    "print(summarize_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a647bfda-920f-4428-86ee-97cf1396c167",
   "metadata": {},
   "source": [
    "How was that response? Does it to include the right kind of information? If so, then continue on to tuning aditional parameters. If not, revisit your prompts and try again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff386a05-130c-4d45-b30a-875b607b06b3",
   "metadata": {},
   "source": [
    "## Chunking Parameters\n",
    "\n",
    "The chunking strategies are very important to tune for each use case.\n",
    "\n",
    "![Chunking Diagram](chunk_duration.png)\n",
    "\n",
    "- `num_frames_per_chunk` controls how many still frames will be selected from each chunk for analysis. These frames are the input to the VLM for building an understanding of the video.\n",
    "\n",
    "- `chunk_overlap_duration` can also be added to the summarization request to configure overlap between chunks. This increases accuracy at chunk boundaries.\n",
    "\n",
    "- `chunk_duration` (also known as chunk size) is very important to tune based on the use case. The chunk size determines the temporal granularity at which the VLM will view the video.\n",
    "\n",
    "\n",
    "Longer chunks result in fewer frames being send to the VLM for analysis. \n",
    "This causes less granularity in your summaries. However, longer chunks increase the odds that important events happen away from chunk boundaries. They also decrease compute time.\n",
    "\n",
    "To understand how these parameters affect the final output, change the values in this widget. Find some that look good and run the next cell. How were the results impacted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55f81e55-17f7-4196-a68c-c5066e123d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea074112c3824035b06c9ad1f9a18b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=10, description='num_frames_per_chunk', layout=Layout(width='500â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(num_frames_per_chunk, chunk_duration, chunk_overlap_duration) = \\\n",
    "    wizards.tune_chunks(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66e97a33-e5fb-4198-a7b8-4a39bd09787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Code: 200\n",
      "**Bridge Condition Report**\n",
      "==========================\n",
      "\n",
      "### Cosmetic\n",
      "\n",
      "* 30.0-57.0: The bridge has a lot of rust on it.\n",
      "* 60.0-87.0: Rusting, paint chipping, and graffiti are present.\n",
      "* 90.0-117.0: The bridge has cracked concrete, peeling paint, and graffiti.\n",
      "* 120.0-147.0: Rust on the metal beam, graffiti, and concrete surface cracks and stains are visible.\n",
      "* 150.00-177.00: Rust on the metal beam, dirt and debris on the concrete surface, and graffiti on the right side are present.\n",
      "\n",
      "### Structural\n",
      "\n",
      "* 60.0-87.0: No visible signs of structural damage or significant wear.\n",
      "* 120.0-147.0: No visible signs of structural damage or significant wear.\n",
      "\n",
      "### Vegetation Overgrowth\n",
      "\n",
      "* 60.0-87.0: Vegetation growth is present.\n",
      "* 90.0-117.0: Overgrown vegetation is visible.\n",
      "* 120.0-147.0: Vegetation growth is present.\n",
      "* 150.00-177.00: Vegetation growth is present on the left side.\n",
      "\n",
      "### Vandalism\n",
      "\n",
      "* 60.0-87.0: Graffiti is present.\n",
      "* 90.0-117.0: Graffiti is visible.\n",
      "* 120.0-147.0: Graffiti is present.\n",
      "* 150.00-177.00: Graffiti is present on the right side.\n",
      "\n",
      "Note: The timestamps are in the format `<start_time> - <end_time>`.\n"
     ]
    }
   ],
   "source": [
    "# create a summary with selected values\n",
    "summarize_response = vss_api_call(\"summarize\", verb=\"post\", json=body)\n",
    "print(summarize_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a6a9e8-6a9c-480e-a772-dc921e367f3d",
   "metadata": {},
   "source": [
    "Is that better or worse? The decision is up to you. If you wan't some advice, or just want to compare notes, check out these **hints**.\n",
    "\n",
    "<details>\n",
    "    <summary><b>HINTS</b></summary>\n",
    "\n",
    "    Using the recomended prompts and the starting settings, the fidelity of the results is already acceptable. Howver, the input video has hard breaks every 30 seconds. This causes very siloed responses. To accomodate this, while not increasing the fidelity more than necessary:\n",
    "    \n",
    "    - increase `chunk_duration_overlap` to 5 to overlap video boundaries\n",
    "    - increase `chunk_duration` to 35 to maintain 60 total frames\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e8250f-a0dd-4c20-8453-d399de8da134",
   "metadata": {},
   "source": [
    "## Inference Time Model Tuning\n",
    "\n",
    "The summarize API also accepts parameters to control the LLM during summary generation. The important ones to note are:\n",
    "\n",
    "- `max_tokens` controls the maximum length of summary generation. This is a hard cutoff and does not change model output. Typically, `1024` is accetable, but smaller values could result in lower costs.\n",
    "- `temperature` and `top_p` parameters influence the probabilities when choosing the next output token. Generally, lower values tend towards more consistent, but less insightful, responses.\n",
    "- `seed` helps control the repeatability of outputs by steering random number generation. Pinning this to a specific value helps us test the changes of other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abd92b8b-1161-4ce1-b048-6887ff0e48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "body[\"max_tokens\"] = 1024 \n",
    "body[\"temperature\"] = 0.9  # typical range: 0 -> 1\n",
    "body[\"top_p\"] = 0.9  # typical range: 0 -> 1\n",
    "body[\"seed\"] = 1  # pinned to a constant value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d1b32a1-4ada-4f56-84fe-e187789b6377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Code: 200\n",
      "**Bridge Condition Report**\n",
      "==========================\n",
      "\n",
      "**Cosmetic Concerns**\n",
      "--------------------\n",
      "\n",
      "* 0:30-0:57: Rust on the bridge\n",
      "* 1:00-1:27: Rusting, paint chipping, vegetation growth, graffiti, lack of proper lighting\n",
      "* 2:00-2:27: Rust on the steel beam, graffiti, vegetation growth, stains on the concrete\n",
      "* 2:30-2:57: Rust on the metal beam, graffiti, vegetation growth on the bridge, dirt and debris on the surface\n",
      "\n",
      "**Structural Condition**\n",
      "-----------------------\n",
      "\n",
      "* 1:00-1:27: No visible signs of structural damage or significant wear\n",
      "* 2:00-2:27: No visible signs of structural damage or significant wear\n",
      "* 2:30-2:57: No visible signs of structural damage or significant wear\n",
      "\n",
      "**Vegetation Overgrowth**\n",
      "-------------------------\n",
      "\n",
      "* 1:00-1:27: Vegetation growth\n",
      "* 1:30-1:57: Overgrown vegetation\n",
      "* 2:00-2:27: Vegetation growth\n",
      "* 2:30-2:57: Vegetation growth on the bridge\n",
      "\n",
      "**Vandalism**\n",
      "-------------\n",
      "\n",
      "* 1:00-1:27: Graffiti\n",
      "* 1:30-1:57: Graffiti\n",
      "* 2:00-2:27: Graffiti\n",
      "* 2:30-2:57: Graffiti\n",
      "\n",
      "**Other Concerns**\n",
      "------------------\n",
      "\n",
      "* 1:00-1:27: Lack of proper lighting, need for regular inspection of guardrails\n",
      "* 2:00-2:27: Missing guardrail\n",
      "* 2:30-2:57: Adequate lighting\n"
     ]
    }
   ],
   "source": [
    "# create a summary with selected values\n",
    "summarize_response = vss_api_call(\"summarize\", verb=\"post\", json=body)\n",
    "print(summarize_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b037d65-c33b-4de9-aa1b-2a22e23fea39",
   "metadata": {},
   "source": [
    "When the model is consistently returning desirable results, the blueprint has been fine tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe604f-61db-4fe1-919c-acb382eee398",
   "metadata": {},
   "source": [
    "# ðŸ¥³ Complete\n",
    "\n",
    "The VSS Blueprint has been fully customized. Feel free to save and close this file and return to the workshop instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724498c5-625f-41b8-8d20-3bb8aa96c01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
